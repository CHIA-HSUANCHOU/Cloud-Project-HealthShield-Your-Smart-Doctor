from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional
import shap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import joblib
import io
import base64

app = FastAPI()

# ---------------------------------------------------------
# 1. è¼‰å…¥æ¨¡å‹èˆ‡åƒæ•¸åŒ…
# ---------------------------------------------------------
# æ³¨æ„ï¼šåœ¨ Docker è£¡ï¼Œè·¯å¾‘å°±æ˜¯ç•¶å‰ç›®éŒ„
#try:
pipeline = joblib.load("nhanes_pipeline_XGBoost.pkl")
model = pipeline["model"]       # æ‚¨çš„ XGBoost æ¨¡å‹
stats = pipeline["imputer_stats"]
scaler = pipeline["scaler"]

# ğŸ”¥ é—œéµä¿®æ”¹ï¼šä¸è¦å¾ pickle è®€ï¼Œæˆ‘å€‘ç¾å ´ç”¨æ¨¡å‹å»ºç«‹ä¸€å€‹æ–°çš„ï¼
print("âš¡ æ­£åœ¨åˆå§‹åŒ– SHAP Explainer...")
print("â˜… â˜… â˜… æ–°ç¨‹å¼ç¢¼è¼‰å…¥ç¢ºèªï¼šæˆ‘æ˜¯æœ€æ–°ç‰ˆçš„ main.pyï¼ â˜… â˜… â˜…")  # <--- åŠ é€™è¡Œ
try:
    # é‡å° XGBoost æ¨¡å‹ï¼Œä½¿ç”¨ TreeExplainer æ˜¯æœ€å¿«æœ€ç©©çš„
    explainer = shap.TreeExplainer(model)
    print("âœ… SHAP Explainer åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âš ï¸ Explainer åˆå§‹åŒ–å¤±æ•—: {e}")
    explainer = None

shap_plots = pipeline.get("shap_plots") # æ‹¿é å…ˆç•«å¥½çš„åœ–
print("âœ… æ¨¡å‹èˆ‡ Pipeline è¼‰å…¥æˆåŠŸ")
#except Exception as e:
#    print(f"âŒ è¼‰å…¥å¤±æ•—: {e}")
    # ç‚ºäº†é˜²æ­¢ App å´©æ½°ï¼Œé€™è£¡å¯èƒ½æœƒéœ€è¦è™•ç†ï¼Œä½†åœ¨ Demo å‰è«‹ç¢ºä¿æª”æ¡ˆå­˜åœ¨

# ---------------------------------------------------------
# 2. å®šç¾©è³‡æ–™è™•ç†å‡½å¼ (é‡ç¾è¨“ç·´æ™‚çš„é‚è¼¯)
# ---------------------------------------------------------
def apply_imputation(df, stats):
    """
    ã€é€šç”¨ã€‘Training å’Œ Inference éƒ½å¯ä»¥ç”¨
    ä½¿ç”¨å‚³å…¥çš„ stats å­—å…¸ä¾†å¡«è£œï¼Œè€Œä¸æ˜¯é‡æ–°è¨ˆç®—
    """
    df = df.copy()

    # --- èº«é«”æ¸¬é‡è¤‡é›œé‚è¼¯ ---
    median_h = stats.get("BMXHT")
    median_w = stats.get("BMXWT")

    if "BMXWAIST" in df.columns:
        df["BMXWAIST"] = df["BMXWAIST"].fillna(stats.get("BMXWAIST"))

    # Case 1 & 2 & 3 (å…¬å¼å›æ¨é‚è¼¯)
    # é€™è£¡ç›´æ¥å¥—ç”¨ä½ åŸæœ¬çš„é‚è¼¯ï¼Œä½†å¡«è£œå€¼æ”¹ç”¨ stats è£¡çš„
    if all(col in df.columns for col in ["BMXHT", "BMXWT", "BMXBMI"]):
        print("  [Body Measures] åŸ·è¡Œèº«é«˜ã€é«”é‡ã€BMI è¤‡é›œé‚è¼¯å¡«è£œ...")

        # æº–å‚™è®Šæ•¸ (H:èº«é«˜cm, W:é«”é‡kg, B:BMI)
        # å…ˆè¨ˆç®—å…¨é«”çš„ä¸­ä½æ•¸ (Median)ï¼Œç”¨æ–¼ç¨å¾Œå¡«è£œ
        median_h = df["BMXHT"].median()
        median_w = df["BMXWT"].median()
        # æ³¨æ„ï¼šè…°åœæ˜¯ç¨ç«‹å¡«è£œ
        if "BMXWAIST" in df.columns:
            df["BMXWAIST"] = df["BMXWAIST"].fillna(df["BMXWAIST"].median())

        # -------------------------------------------------------
        # Case 1: åªæœ‰å…¶ä¸­ä¸€å€‹ç¼ºï¼Œä¸”å…¶é¤˜å…©å€‹æœ‰ï¼šç”¨å…¬å¼å›æ¨
        # -------------------------------------------------------
        # 1.1 ç¼º BMI (æœ‰ H, W) -> B = W / (H/100)^2
        mask_miss_b = df["BMXBMI"].isna() & df["BMXHT"].notna() & df["BMXWT"].notna()
        df.loc[mask_miss_b, "BMXBMI"] = df.loc[mask_miss_b, "BMXWT"] / ((df.loc[mask_miss_b, "BMXHT"] / 100) ** 2)

        # 1.2 ç¼º é«”é‡ (æœ‰ H, B) -> W = B * (H/100)^2
        mask_miss_w = df["BMXWT"].isna() & df["BMXHT"].notna() & df["BMXBMI"].notna()
        df.loc[mask_miss_w, "BMXWT"] = df.loc[mask_miss_w, "BMXBMI"] * ((df.loc[mask_miss_w, "BMXHT"] / 100) ** 2)

        # 1.3 ç¼º èº«é«˜ (æœ‰ W, B) -> H = 100 * sqrt(W / B)
        mask_miss_h = df["BMXHT"].isna() & df["BMXWT"].notna() & df["BMXBMI"].notna()
        df.loc[mask_miss_h, "BMXHT"] = 100 * np.sqrt(df.loc[mask_miss_h, "BMXWT"] / df.loc[mask_miss_h, "BMXBMI"])

        # -------------------------------------------------------
        # Case 2: ä¸‰å€‹ä¸­æœ‰å…©å€‹ç¼º
        # -------------------------------------------------------
        # 2.1 èº«é«˜ã€é«”é‡ç¼º (æœ‰ BMI)ï¼šå…ˆç”¨ä¸­ä½æ•¸å¡«è£œé«”é‡ï¼Œç”¨å…¬å¼æ¨ç®—èº«é«˜
        mask_miss_hw = df["BMXHT"].isna() & df["BMXWT"].isna() & df["BMXBMI"].notna()
        # Step 1: å¡«é«”é‡ (ä¸­ä½æ•¸)
        df.loc[mask_miss_hw, "BMXWT"] = median_w
        # Step 2: æ¨èº«é«˜ (å…¬å¼)
        df.loc[mask_miss_hw, "BMXHT"] = 100 * np.sqrt(df.loc[mask_miss_hw, "BMXWT"] / df.loc[mask_miss_hw, "BMXBMI"])

        # 2.2 èº«é«˜ã€BMI ç¼º (æœ‰ é«”é‡)ï¼šå…ˆç”¨ä¸­ä½æ•¸å¡«è£œèº«é«˜ï¼Œå†è¨ˆç®— BMI
        mask_miss_hb = df["BMXHT"].isna() & df["BMXBMI"].isna() & df["BMXWT"].notna()
        # Step 1: å¡«èº«é«˜ (ä¸­ä½æ•¸)
        df.loc[mask_miss_hb, "BMXHT"] = median_h
        # Step 2: ç®— BMI
        df.loc[mask_miss_hb, "BMXBMI"] = df.loc[mask_miss_hb, "BMXWT"] / ((df.loc[mask_miss_hb, "BMXHT"] / 100) ** 2)

        # 2.3 é«”é‡ã€BMI ç¼º (æœ‰ èº«é«˜)ï¼šå…ˆç”¨ä¸­ä½æ•¸å¡«è£œé«”é‡ï¼Œå†è¨ˆç®— BMI
        mask_miss_wb = df["BMXWT"].isna() & df["BMXBMI"].isna() & df["BMXHT"].notna()
        # Step 1: å¡«é«”é‡ (ä¸­ä½æ•¸)
        df.loc[mask_miss_wb, "BMXWT"] = median_w
        # Step 2: ç®— BMI
        df.loc[mask_miss_wb, "BMXBMI"] = df.loc[mask_miss_wb, "BMXWT"] / ((df.loc[mask_miss_wb, "BMXHT"] / 100) ** 2)

        # -------------------------------------------------------
        # Case 3: ä¸‰å€‹éƒ½ç¼º
        # -------------------------------------------------------
        # ç”¨ä¸­ä½æ•¸å¡«è£œèº«é«˜ã€é«”é‡ï¼Œå†è¨ˆç®—å¡«è£œå¾Œçš„ bmi
        mask_miss_all = df["BMXHT"].isna() & df["BMXWT"].isna() & df["BMXBMI"].isna()
        df.loc[mask_miss_all, "BMXHT"] = median_h
        df.loc[mask_miss_all, "BMXWT"] = median_w
        df.loc[mask_miss_all, "BMXBMI"] = median_w / ((median_h / 100) ** 2)

    # è¡€å£“è¨ˆç®—
    #sys_cols = [c for c in ["BPXSY1", "BPXSY2", "BPXSY3"] if c in df.columns]
    #dia_cols = [c for c in ["BPXDI1", "BPXDI2", "BPXDI3"] if c in df.columns]

    #if sys_cols:
    #    df["systolic_avg"] = df[sys_cols].mean(axis=1)
    df["systolic_avg"] = df["systolic_avg"].fillna(stats.get("systolic_avg"))

    #if dia_cols:
    #    df["diastolic_avg"] = df[dia_cols].mean(axis=1)
    df["diastolic_avg"] = df["diastolic_avg"].fillna(stats.get("diastolic_avg"))

    # Lab å¡«è£œ
    lab_vars = ["LBXGLU", "LBXIN", "LBXGH", "LBXTC", "LBDHDD", "LBDLDL", "LBXTR"]
    for col in lab_vars:
        if col in df.columns:
            df[col] = df[col].fillna(stats.get(col))

    # ç”Ÿæ´»ç¿’æ…£è¦å‰‡ (å¸è¸ã€é£²é…’ã€é¡åˆ¥)
    if "SMQ020" in df.columns and "RIDAGEYR" in df.columns:
        df.loc[(df["RIDAGEYR"] < 20) & (df["SMQ020"].isna()), "SMQ020"] = 2
        df.loc[(df["RIDAGEYR"] >= 20) & (df["SMQ020"].isna()), "SMQ020"] = 3

    if "ALQ130" in df.columns:
        df.loc[df["RIDAGEYR"] < 20, "ALQ130"] = df.loc[df["RIDAGEYR"] < 20, "ALQ130"].fillna(0)
        df.loc[df["RIDAGEYR"] >= 20, "ALQ130"] = df.loc[df["RIDAGEYR"] >= 20, "ALQ130"].fillna(stats.get("ALQ130_adult"))

    for col in ["MCQ300C", "PAQ650", "PAQ665"]:
        if col in df.columns:
            df[col] = df[col].fillna(3)

    # ç¡çœ 
    if "SLD012" in df.columns and "SLD010H" in df.columns:
        df["Sleep_Hours"] = df["SLD012"].combine_first(df["SLD010H"])
    elif "SLD012" in df.columns:
        df["Sleep_Hours"] = df["SLD012"]
    elif "SLD010H" in df.columns:
        df["Sleep_Hours"] = df["SLD010H"]
    else:
        df["Sleep_Hours"] = np.nan
    df["Sleep_Hours"] = df["Sleep_Hours"].fillna(stats.get("Sleep_Hours"))

    if "HUQ010" in df.columns:
        df["HUQ010"] = df["HUQ010"].fillna(stats.get("HUQ010"))

    return df

def plot_to_base64(fig):
    """å°‡ Matplotlib åœ–ç‰‡è½‰ç‚º Base64 å­—ä¸²"""
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches='tight', dpi=150)
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("utf-8")

# ---------------------------------------------------------
# 3. å®šç¾© API è¼¸å…¥æ ¼å¼ (NHANES Codes)
# ---------------------------------------------------------
# å®šç¾©è¼¸å…¥æ ¼å¼ (æ ¹æ“šä½ çš„ X_train åŸå§‹æ¬„ä½)
class InputData(BaseModel):
    # --- 1. åŸºæœ¬äººå£å­¸ (Demographics) ---
    RIDAGEYR: float          # å¹´é½¡
    RIAGENDR: float          # æ€§åˆ¥ (1=ç”·, 2=å¥³)

    # --- 2. èº«é«”æ¸¬é‡ (Body Measures) ---
    # è¨­å®š = None ä»£è¡¨é€™äº›æ¬„ä½æ˜¯é¸å¡«çš„ (å…è¨±å‰ç«¯é€ä¾† null)
    # å› ç‚ºä½ çš„å‰ç«¯æœ‰ "I don't know" é¸é …ï¼Œå¾Œç«¯å¿…é ˆå…è¨±æ¥æ”¶ None
    BMXHT: Optional[float] = None       # èº«é«˜
    BMXWT: Optional[float] = None       # é«”é‡
    BMXBMI: Optional[float] = None      # BMI (å‰ç«¯æœ‰ç®—å¥½å‚³éä¾†)
    BMXWAIST: Optional[float] = None    # è…°åœ

    # --- 3. è¡€å£“ (Blood Pressure) ---
    # æ³¨æ„ï¼šé€™è£¡å°æ‡‰ä½ å‰ç«¯ NAME_MAPPING çš„ key
    systolic_avg: Optional[float] = None 
    diastolic_avg: Optional[float] = None

    # --- 4. è¡€æ¶²æª¢é©— (Lab Tests) ---
    LBXGLU: Optional[float] = None      # ç©ºè…¹è¡€ç³–
    LBXIN: Optional[float] = None       # èƒ°å³¶ç´ 
    LBXGH: Optional[float] = None       # ç³–åŒ–è¡€è‰²ç´  HbA1c
    LBXTC: Optional[float] = None       # ç¸½è†½å›ºé†‡
    LBDHDD: Optional[float] = None      # HDL
    LBDLDL: Optional[float] = None      # LDL
    LBXTR: Optional[float] = None       # ä¸‰é…¸ç”˜æ²¹è„‚

    # --- 5. ç”Ÿæ´»ç¿’æ…£ (Lifestyle) ---
    SMQ020: Optional[float] = None      # å¸è¸ (1=Yes, 2=No)
    ALQ130: Optional[float] = None      # é£²é…’é‡
    
    # é‹å‹• (æ³¨æ„ï¼šéœ€å°ç…§ä½ è¨“ç·´æ™‚æ˜¯ç”¨ PAQ650 é‚„æ˜¯ 665)
    # æ ¹æ“šä½ çš„å‰ç«¯ mappingï¼šModerate -> PAQ665, Vigorous -> PAQ650
    PAQ665: Optional[float] = None      # ä¸­å¼·åº¦é‹å‹•
    PAQ650: Optional[float] = None      # é«˜å¼·åº¦é‹å‹•
    
    MCQ300C: Optional[float] = None     # å®¶æ—å²
    HUQ010: Optional[float] = None      # è‡ªè©•å¥åº· (1-5)
    Sleep_Hours: Optional[float] = None # ç¡çœ æ™‚æ•¸

# ---------------------------------------------------------
# 4. API è·¯ç”±
# ---------------------------------------------------------
# API 1: å‚³é€å…¨åŸŸè§£é‡‹åœ–çµ¦å‰ç«¯
@app.get("/global_shap")
def get_global_shap():
    return shap_plots  # ç›´æ¥å›å‚³ base64 å­—ä¸²


# API 2: é æ¸¬ (é€™æ˜¯åŸæœ¬çš„ predictï¼Œæˆ‘å€‘è¦åŠ å…¥å–®ä¸€è§£é‡‹é‚è¼¯)
@app.post("/predict")
def predict(data: InputData):
    # A. è½‰ DataFrame
    input_dict = data.dict()
    df = pd.DataFrame([input_dict])

    # B. æ¸…æ´—ç‰¹æ®Šä»£ç¢¼ (7, 9 -> NaN)
    for group, cols in pipeline["nan_map"].items():
        vals = pipeline["nan_values"][group]
        for c in cols:
            if c in df.columns:
                df[c] = df[c].replace(vals, np.nan)

    # C. å¡«è£œèˆ‡ç‰¹å¾µå·¥ç¨‹
    df = apply_imputation(df, stats)

    # D. Rename & Drop
    drop_cols = ['SLD012', 'SLD010H', 'BPXDI1', 'BPXDI2', 'BPXDI3', 'BPXSY1', 'BPXSY2', 'BPXSY3']
    df = df.drop(columns=drop_cols, errors='ignore')
    df = df.rename(columns=pipeline["rename_dict"])

    # E. Scaling
    cols_to_scale = pipeline["minmax_cols"]
    df[cols_to_scale] = scaler.transform(df[cols_to_scale])

    # F. Encoding & Alignment
    cols_to_encode = pipeline["onehot_cols"]
    df = pd.get_dummies(df, columns=cols_to_encode)
    # è£œé½Šç¼ºå°‘çš„æ¬„ä½ (é‡è¦ï¼)
    df = df.reindex(columns=pipeline["final_columns"], fill_value=0)

    # G. é æ¸¬
    # 1. é æ¸¬æ©Ÿç‡
    # predict_proba å›å‚³ [[ä¸æ‚£ç—…æ©Ÿç‡, æ‚£ç—…æ©Ÿç‡]]
    prob = model.predict_proba(df)[0][1]
    
    # 2. è¨ˆç®—é€™å€‹äººçš„ SHAP (Local Explanation)
    # æ³¨æ„ï¼šTreeExplainer é€Ÿåº¦å¾ˆå¿«ï¼Œç®—ä¸€ç­†æ²’å•é¡Œ
    shap_data = {}
    try:
        # è¨ˆç®— SHAP values
        shap_values_local = explainer(df, check_additivity=False)
        
        # XGBoost çš„ output é€šå¸¸åªæœ‰ä¸€ç¶­ (ä¸åƒ Random Forest æœ‰ Class 0/1)
        # å¦‚æœæ˜¯äºŒå…ƒåˆ†é¡ï¼ŒXGBoost TreeExplainer é è¨­è¼¸å‡º log-odds
        
        # è™•ç†å–®ç­†è³‡æ–™ (å–å‡ºç¬¬ 0 ç­†)
        single_explanation = shap_values_local[0]

        # 1. ç¹ªè£½ Waterfall Plot (å­˜æˆåœ–ç‰‡)
        fig_waterfall = plt.figure(figsize=(8, 6))
        shap.plots.waterfall(single_explanation, show=False, max_display=10)
        shap_data["waterfall"] = plot_to_base64(fig_waterfall)

        # 2. ç¹ªè£½ Force Plot (å­˜æˆ HTML)
        force_plot = shap.plots.force(
            single_explanation, 
            matplotlib=False
        )
        shap_data["force_html"] = f"<head>{shap.getjs()}</head><body>{force_plot.html()}</body>"
        
    except Exception as e:
        print(f"SHAP Error: {e}")
        shap_data["error"] = str(e)
    

    # H. ç”¢ç”Ÿå»ºè­° (é€™æ˜¯åŠ åˆ†é¡Œï¼å‰å¾Œç«¯åˆ†é›¢çš„å¥½è™•)
    advice = []
    if prob > 0.7:
        advice.append("âš ï¸ é«˜åº¦é¢¨éšªè­¦å‘Šï¼šå»ºè­°è«®è©¢é†«ç”Ÿã€‚")
    elif prob > 0.3:
        advice.append("âš ï¸ ä¸­åº¦é¢¨éšªè­¦å‘Šï¼šå»ºè­°å®šæœŸè¿½è¹¤ã€‚")
    
    # é€™è£¡çš„ df['bmi'] æ˜¯æ¨™æº–åŒ–éçš„ï¼Œè‹¥è¦åˆ¤æ–·å»ºè­°ï¼Œæœ€å¥½ç”¨ input_dict['BMXBMI'] åŸå§‹å€¼
    if input_dict['BMXBMI'] and input_dict['BMXBMI'] > 24:
        advice.append("ğŸ’ª é«”é‡ç®¡ç†ï¼šBMI åé«˜ï¼Œå»ºè­°æ§åˆ¶é£²é£Ÿèˆ‡é‹å‹•ã€‚")

    # 3. åŸ·è¡Œä½ åŸæœ¬çš„ã€Œåˆ†çµ„é‚è¼¯ã€ (å› ç‚ºç¾åœ¨åªæœ‰ä¸€ç­†ï¼Œé‚è¼¯è¦å¾®èª¿æˆ–å°è£æˆå‡½å¼)
    # ç‚ºäº†ç°¡åŒ– Demoï¼Œé€™è£¡å¯ä»¥ç›´æ¥å›å‚³æœ€é‡è¦çš„ç‰¹å¾µåç¨±
    # è‹¥è¦å®Œæ•´å¾©åˆ»ä½ çš„åˆ†çµ„é‚è¼¯ï¼Œå»ºè­°æŠŠé‚£æ®µ base_map çš„ç¨‹å¼ç¢¼å°è£æˆå‡½å¼æ”¾åœ¨é€™è£¡å‘¼å«
    return {"probability": float(prob), "advice": advice, "shap_local": shap_data}
